{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below code parses all the xml files \n",
    "#All the news articles and relevant metadata are put into the all_news_result list\n",
    "#All the commentary articles and relevant metadata are put into the all_commentary_result list\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import html2text\n",
    "from pprint import pprint\n",
    "import json, os, csv, re\n",
    "\n",
    "escape_illegal_xml_characters = lambda x: re.sub(u'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1F\\uD800-\\uDFFF\\uFFFE\\uFFFF]', '', x)\n",
    "all_news = []\n",
    "all_commentary = []\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    for name in files:\n",
    "        if '.xml' in name:\n",
    "            if \"News\" in root:\n",
    "                all_news.append(os.path.join(root, name))\n",
    "            if \"Commentary\" in root:\n",
    "                all_commentary.append(os.path.join(root, name))\n",
    "                \n",
    "def commentary_parsing(root):\n",
    "    count = 0\n",
    "    while root[0][count].tag != 'item':\n",
    "        count += 1\n",
    "    assert root[0][-1].tag == 'item'\n",
    "    for item in root[0][count:]:\n",
    "        tags = []\n",
    "        affiliation = ''\n",
    "        author = ''\n",
    "        contentEncoded = ''\n",
    "        for child in item:\n",
    "            if child.tag == 'title':\n",
    "                title = child.text\n",
    "            elif child.tag == 'link':\n",
    "                link = child.text\n",
    "            elif child.tag == '{http://purl.org/rss/1.0/modules/content/}encoded':\n",
    "                contentEncoded = child.text\n",
    "            elif child.tag == 'pubDate':\n",
    "                date = child.text\n",
    "            elif child.tag == 'category':\n",
    "                if child.text != 'Uncategorized' and 'affiliation' not in child.text.lower() and 'author' not in child.text.lower():\n",
    "                    tags.append(child.text)\n",
    "                elif 'affiliation:' in child.text.lower():\n",
    "                    affiliation = re.sub(\"affiliation:\", \"\", child.text, flags=re.I)\n",
    "                elif 'author:' in child.text.lower():\n",
    "                    author = re.sub(\"author:\", \"\", child.text, flags=re.I)\n",
    "        all_tags = ', '.join(tags)\n",
    "        result = [title,date,all_tags,author,affiliation,link,contentEncoded]\n",
    "        all_commentary_result.append(result)\n",
    "        \n",
    "        \n",
    "def news_parsing(root):\n",
    "    count = 0\n",
    "    while root[0][count].tag != 'item':\n",
    "        count += 1\n",
    "    assert root[0][-1].tag == 'item'\n",
    "    for item in root[0][count:]:\n",
    "        tags = []\n",
    "        affiliation = ''\n",
    "        author = ''\n",
    "        contentEncoded = ''\n",
    "        for child in item:\n",
    "            if child.tag == 'title':\n",
    "                title = child.text\n",
    "            elif child.tag == 'link':\n",
    "                link = child.text\n",
    "            elif child.tag == '{http://purl.org/rss/1.0/modules/content/}encoded':\n",
    "                contentEncoded = child.text\n",
    "            elif child.tag == 'pubDate':\n",
    "                date = child.text\n",
    "            elif child.tag == 'category':\n",
    "                if child.text != 'Uncategorized' and 'affiliation' not in child.text.lower() and 'author' not in child.text.lower():\n",
    "                    tags.append(child.text)\n",
    "                elif 'affiliation:' in child.text.lower():\n",
    "                    affiliation = re.sub(\"affiliation:\", \"\", child.text, flags=re.I)\n",
    "                elif 'author:' in child.text.lower():\n",
    "                    author = re.sub(\"author:\", \"\", child.text, flags=re.I)\n",
    "        all_tags = ', '.join(tags)\n",
    "        result = [title,date,all_tags,author,affiliation,link,contentEncoded]\n",
    "        all_news_result.append(result)\n",
    "        \n",
    "        \n",
    "all_commentary_result = []\n",
    "for i in all_commentary:\n",
    "    try:\n",
    "        root = ET.parse(i).getroot()\n",
    "        commentary_parsing(root)\n",
    "    except:\n",
    "        content = ''\n",
    "        with open (i,'r+', encoding='utf-8') as fp:\n",
    "            content = fp.read()\n",
    "        fp.close()\n",
    "        parser = ET.XMLParser(encoding=\"utf-8\")\n",
    "        root = ET.fromstring(escape_illegal_xml_characters(content), parser=parser)\n",
    "        commentary_parsing(root)\n",
    "        continue\n",
    "        \n",
    "all_news_result = []\n",
    "for i in all_news:\n",
    "    try:\n",
    "        root = ET.parse(i).getroot()\n",
    "        news_parsing(root)\n",
    "    except:\n",
    "        content = ''\n",
    "        with open (i,'r+', encoding='utf-8') as fp:\n",
    "            content = fp.read()\n",
    "        fp.close()\n",
    "        parser = ET.XMLParser(encoding=\"utf-8\")\n",
    "        root = ET.fromstring(escape_illegal_xml_characters(content), parser=parser)\n",
    "        news_parsing(root)\n",
    "        continue\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Converts the lists into pandas dataframes\n",
    "allNews = pd.DataFrame(all_news_result, columns = [\"Title\", \"PubDate\", \"Tags\",\"Author\",\"Affiliation\",\"Link\",\"Text\"])\n",
    "allCommentary = pd.DataFrame(all_commentary_result, columns = [\"Title\", \"PubDate\", \"Tags\",\"Author\",\"Affiliation\",\"Link\",\"Text\"])\n",
    "#Creates a new column where the processed text will be placed, for now it just copies all the text\n",
    "allNews['Processed'] = allNews['Text']\n",
    "allCommentary['Processed'] = allCommentary['Text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing function\n",
    "#problems with index 23 in all_commentary\n",
    "def processText(oldString):\n",
    "    newString = str(oldString)\n",
    "    #First remove the author information\n",
    "    newString = re.sub(\"^.*?:<br /><br />&quot;|^.*?: <br /><br />&quot;\", '', newString)  \n",
    "    \n",
    "    \n",
    "    newString = re.sub(\"^.*?]: &quot;\", '', newString)  \n",
    "    newString = re.sub(\"^.*?<span style=.*?><b>\", '', newString)  \n",
    "    newString = re.sub(\"^.*?<font SIZE=3><b>\", '', newString)  \n",
    "    \n",
    "    newString = re.sub('^.*?\\n\\n<hr size=\"1\" />\\n\\n<span style=\"font-size: medium;\"><b>', '', newString)\n",
    "    if(newString.find(\"<br /><br /><em>\") != -1):\n",
    "        newString = newString[:newString.find(\"<br /><br /><em>\")]\n",
    "    if(newString.find(\"<p><em><br />\") != -1):\n",
    "        newString = newString[:newString.find(\"<p><em><br />\")]\n",
    "    if(newString.find(\"&quot; [\") != -1):\n",
    "        newString = newString[:newString.find(\"&quot; [\")]\n",
    "    if(newString.find(\"<em>............................................................*\") != -1):\n",
    "        newString = newString[:newString.find(\"<em>............................................................*\")]\n",
    "    \n",
    "    #Next remove, the paragraph and em tags\n",
    "    newString = re.sub(\"<p>|</p>|<em>|</em>\", '', newString)\n",
    "    #Replace the newlines with spaces\n",
    "    newString = re.sub(\"\\n\", ' ', newString)\n",
    "    #Get rid of the links using the <a> tag, of the format <a href ...> text to be linked </a>\n",
    "    newString = re.sub(\"</a>|<a.*?>\", '', newString)   \n",
    "    #Replace any other tags, some of them are br, some of them are <blockquote> \n",
    "    #Also, replace &emdash; and &nbsp; and replace anything in brackets [stuff here]\n",
    "    newString = re.sub(\"<br />|&.*?;|<.*?>\", '', newString)  \n",
    "    newString = re.sub(\"--------\", '', newString)  \n",
    "    return(newString)\n",
    "    \n",
    "   \n",
    "#Preprocessing function for News articles where there are no authors, need to figure out how to represent [things in brackets]\n",
    "def processNews(oldString):\n",
    "    newString = str(oldString)\n",
    "    #First remove, the paragraph and em tags\n",
    "    newString = re.sub(\"<p>|</p>|<em>|</em>\", '', newString)\n",
    "    #Replace the newlines with spaces\n",
    "    newString = re.sub(\"\\n\", ' ', newString)\n",
    "    #Get rid of the links using the <a> tag, of the format <a href ...> text to be linked </a>\n",
    "    newString = re.sub(\"</a>|<a.*?>\", '', newString)   \n",
    "    #Replace any other tags, some of them are br, some of them are <blockquote> \n",
    "    #Also, replace &emdash; and &nbsp; and replace anything in brackets [stuff here]\n",
    "    newString = re.sub(\"<br />|&.*?;|<.*?>\", '', newString)  \n",
    "    #newString = re.sub(\"\\[.*?]\", '', newString)  ##NEED TO FIGURE OUT REGEX MATCHING FOR []\n",
    "    return(newString)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCommentary['Processed'] = allCommentary.apply(lambda row: processText(row['Text']),axis=1)\n",
    "allNews['Processed'] = allNews.apply(lambda row: processNews(row['Text']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename1 = 'allCommentary'\n",
    "pickle.dump(allCommentary, open(filename1, 'wb'))\n",
    "filename2 = 'allNews'\n",
    "pickle.dump(allNews, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use allCommentary = pickle.load(open('allCommentary', 'rb')) to open up the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCommentary = pickle.load(open('allCommentary', 'rb'))\n",
    "allNews = pickle.load(open('allNews', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
